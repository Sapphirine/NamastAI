{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Bala_HP\\anaconda3\\envs\\namestai\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nhttps://stackoverflow.com/questions/74090972/how-to-stream-video-images-from-python-app-to-a-remote-reactjs-webpage\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\"\"\"\n",
    "https://stackoverflow.com/questions/74090972/how-to-stream-video-images-from-python-app-to-a-remote-reactjs-webpage\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://raw.githubusercontent.com/balachander-sa/Namestai_streamlit/main/Movenet_lightning_unit8.tflite\"\n",
    "# Download the TFLite model from GitHub\n",
    "response = requests.get(model_url)\n",
    "model_content = response.content\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_content=model_content)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[nose,\n",
    "left eye,\n",
    "right eye, \n",
    "left ear,\n",
    "right ear, \n",
    "left shoulder,\n",
    "right shoulder,\n",
    "left elbow, \n",
    "right elbow,\n",
    "left wrist,\n",
    "right wrist, \n",
    "left hip,\n",
    "right hip,\n",
    "left knee,\n",
    "right knee,\n",
    "left ankle,\n",
    "right ankle]\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "1,6,8-------left shoulder angle----LSA\n",
    "1,7,9-------right shoulder angle---RSA\n",
    "6,8,10------left elbow angle-------LEA\n",
    "7,9,11------right elbow angle------REA\n",
    "6,12,14-----left hip angle---------LHA\n",
    "7,13,15-----right hip angle--------RHA\n",
    "12,14,16----left knee angle--------LKA\n",
    "13,15,17----right knee angle-------RKA\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Movenet reference picture](Movenet_ref.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame1.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    keypoint_indx = [5,6,7,8,11,12,13,14]\n",
    "\n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 6, (0,255,0), -1)\n",
    "\n",
    "    for idx in keypoint_indx:\n",
    "        kp = shaped[idx]\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 8, (255,0,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_Keypoints(frame, interpreter):\n",
    "\n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize(np.expand_dims(img, axis=0), [192,192])\n",
    "    input_image = tf.cast(img, dtype=tf.uint8)\n",
    "\n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    keypoints_final = keypoints_with_scores[0,0].T[0:2]\n",
    "    draw_keypoints(frame, keypoints_with_scores, 0.01)\n",
    "\n",
    "    return frame, keypoints_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "\n",
    "    AB = np.array(b) - np.array(a)\n",
    "    BC = np.array(c) - np.array(b)\n",
    "\n",
    "    dot_product = np.dot(AB, BC)\n",
    "    magnitude_AB = np.linalg.norm(AB)\n",
    "    magnitude_BC = np.linalg.norm(BC)\n",
    "\n",
    "    cos_theta = dot_product / (magnitude_AB * magnitude_BC)\n",
    "    theta = np.arccos(cos_theta)\n",
    "\n",
    "    # Convert to degrees\n",
    "    angle_degrees = np.degrees(theta)\n",
    "\n",
    "    return angle_degrees        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = \"Preprocessed_images\\Pos1\"  #Input folder\n",
    "Output_folder = \"Output_images\\Pos1\"\n",
    "# Read Image\n",
    "Angle_list = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Read the input image\n",
    "    image_path = os.path.join(folder_path, filename)\n",
    "    frame = cv2.imread(image_path)\n",
    "    frame = cv2.resize(frame, (512,512))\n",
    "\n",
    "    #Getting the annotated image and keypoints\n",
    "    op_image, kp = return_Keypoints(frame, interpreter)\n",
    "    \n",
    "    #Calculating the required angles\n",
    "    LSA = calculate_angle(kp[:,0],kp[:,5],kp[:,7])\n",
    "    RSA = calculate_angle(kp[:,0],kp[:,6],kp[:,8])\n",
    "    LEA = calculate_angle(kp[:,5],kp[:,7],kp[:,9])\n",
    "    REA = calculate_angle(kp[:,6],kp[:,8],kp[:,10])\n",
    "    LHA = calculate_angle(kp[:,5],kp[:,11],kp[:,13])\n",
    "    RHA = calculate_angle(kp[:,6],kp[:,12],kp[:,14])\n",
    "    LKA = calculate_angle(kp[:,11],kp[:,13],kp[:,15])\n",
    "    RKA = calculate_angle(kp[:,12],kp[:,14],kp[:,16])\n",
    "    Angles = [LSA, RSA, LEA, REA, LHA, RHA, LKA, RKA]\n",
    "\n",
    "    # Save the output image\n",
    "    output_image_path = os.path.join(Output_folder, filename)\n",
    "    cv2.imwrite(output_image_path, frame)\n",
    "\n",
    "    # Saving the angles to convert in CSV\n",
    "    Angle_list.append(Angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "angle_array = np.stack(Angle_list)\n",
    "angle_array\n",
    "header_val = [\"LSA\", \"RSA\", \"LEA\", \"REA\", \"LHA\", \"RHA\", \"LKA\", \"RKA\"]\n",
    "format_str = '%.18f'\n",
    "np.savetxt('Angles_pos1.csv', angle_array, delimiter=',', header=','.join(header_val), fmt=format_str, comments='')\n",
    "\n",
    "print(\"CSV file saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "namestai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
